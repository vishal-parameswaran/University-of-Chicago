{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create small sample model files\n",
    "Once we are happy with the model results, we can convert to sklearn pipeline to simplify deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n",
      "[GCC 9.4.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('/home/jupyter/yelp', exist_ok=True)\n",
    "os.makedirs('/home/jupyter/data/yelp/yelp_model', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'https://storage.googleapis.com/msca-bdp-data-open/yelp/'\n",
    "fileName = 'yelp_train_sentiment.json'\n",
    "\n",
    "path = directory + fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.69 s, sys: 645 ms, total: 2.34 s\n",
      "Wall time: 3.38 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(255717, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "yelp = pd.read_json(path, orient='records', lines=True)\n",
    "yelp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp = yelp.sample(frac=0.01, replace=False, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting results\n",
    "label = 0 >> Negative Sentiment  \n",
    "label = 1 >> Positive Sentiment  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cute place.  I wanted it to be good.  Very disappointing.  The chicken fried steak was actual very thin steak with gristle.  The eggs, bacon and hash browns were fine.  But how hard is it to mess ...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I SO thought this was going to be awesome as I've heard great things. Don't know what happened but it was not good. My mother asked what vegetables they had to put in the omelette- LOLLL- and she ...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Called them to come and give me an estimate on my two balconies that need repair.  Daniel came out the 21st of Dec. and said he would send me an email with the estimate later that evening.  No est...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow. We are Cumbrae and Royal Beef fans, and these guys blow them out of the water!  Chicken that tastes like chicken. Never knew most chicken is bleached in Canada. Now I know better!</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I drove from the North Valley to Mesa to have a birthday dinner with one of my girl friends. She picked Peir de Orleans and from what I saw the place didn't seem too bad. A couple bad reviews, but...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      text  \\\n",
       "0  Cute place.  I wanted it to be good.  Very disappointing.  The chicken fried steak was actual very thin steak with gristle.  The eggs, bacon and hash browns were fine.  But how hard is it to mess ...   \n",
       "1  I SO thought this was going to be awesome as I've heard great things. Don't know what happened but it was not good. My mother asked what vegetables they had to put in the omelette- LOLLL- and she ...   \n",
       "2  Called them to come and give me an estimate on my two balconies that need repair.  Daniel came out the 21st of Dec. and said he would send me an email with the estimate later that evening.  No est...   \n",
       "3                 Wow. We are Cumbrae and Royal Beef fans, and these guys blow them out of the water!  Chicken that tastes like chicken. Never knew most chicken is bleached in Canada. Now I know better!   \n",
       "4  I drove from the North Valley to Mesa to have a birthday dinner with one of my girl friends. She picked Peir de Orleans and from what I saw the place didn't seem too bad. A couple bad reviews, but...   \n",
       "\n",
       "   label lang  \n",
       "0      0   en  \n",
       "1      0   en  \n",
       "2      0   en  \n",
       "3      1   en  \n",
       "4      0   en  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the first 5 rows\n",
    "yelp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2557,)\n",
      "(2557,)\n"
     ]
    }
   ],
   "source": [
    "# define X and y\n",
    "X = yelp['text']\n",
    "y = yelp['label']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1917,)\n",
      "(640,)\n",
      "(1917,)\n",
      "(640,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating sklearn pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_nb = make_pipeline(\n",
    "    CountVectorizer(lowercase=False, stop_words='english', ngram_range=(1,3)),\n",
    "    MultinomialNB()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.04 s, sys: 0 ns, total: 1.04 s\n",
      "Wall time: 1.04 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(lowercase=False, ngram_range=(1, 3),\n",
       "                                 stop_words='english')),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time pipe_nb.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 154 ms, sys: 0 ns, total: 154 ms\n",
      "Wall time: 152 ms\n"
     ]
    }
   ],
   "source": [
    "%time y_pred = pipe_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 90.8%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {metrics.accuracy_score(y_test, y_pred) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       319\n",
      "           1       0.94      0.88      0.90       321\n",
      "\n",
      "    accuracy                           0.91       640\n",
      "   macro avg       0.91      0.91      0.91       640\n",
      "weighted avg       0.91      0.91      0.91       640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.29 s, sys: 29 ms, total: 2.32 s\n",
      "Wall time: 2.35 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/jupyter/data/yelp/yelp_model/nb_small.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time dump(pipe_nb, \"/home/jupyter/data/yelp/yelp_model/nb_small.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_logreg = make_pipeline(\n",
    "    CountVectorizer(lowercase=False, stop_words='english', ngram_range=(1,3)),\n",
    "    LogisticRegression(max_iter=1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.57 s, sys: 7.64 s, total: 12.2 s\n",
      "Wall time: 2.94 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(lowercase=False, ngram_range=(1, 3),\n",
       "                                 stop_words='english')),\n",
       "                ('logisticregression', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time pipe_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 268 ms, sys: 340 ms, total: 608 ms\n",
      "Wall time: 188 ms\n"
     ]
    }
   ],
   "source": [
    "%time y_pred = pipe_logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 90.6%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {metrics.accuracy_score(y_test, y_pred) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90       319\n",
      "           1       0.90      0.92      0.91       321\n",
      "\n",
      "    accuracy                           0.91       640\n",
      "   macro avg       0.91      0.91      0.91       640\n",
      "weighted avg       0.91      0.91      0.91       640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.25 s, sys: 28.8 ms, total: 2.28 s\n",
      "Wall time: 2.29 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/jupyter/data/yelp/yelp_model/logreg_small.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time dump(pipe_logreg, \"/home/jupyter/data/yelp/yelp_model/logreg_small.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svm = make_pipeline(\n",
    "    CountVectorizer(lowercase=False, stop_words='english', ngram_range=(1,3)),\n",
    "    SGDClassifier(max_iter=100, tol=None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.4 s, sys: 635 ms, total: 2.03 s\n",
      "Wall time: 1.24 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(lowercase=False, ngram_range=(1, 3),\n",
       "                                 stop_words='english')),\n",
       "                ('sgdclassifier', SGDClassifier(max_iter=100, tol=None))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time pipe_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9109375\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       319\n",
      "           1       0.92      0.90      0.91       321\n",
      "\n",
      "    accuracy                           0.91       640\n",
      "   macro avg       0.91      0.91      0.91       640\n",
      "weighted avg       0.91      0.91      0.91       640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate precision and recall\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.22 s, sys: 15.9 ms, total: 2.24 s\n",
      "Wall time: 2.25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/jupyter/data/yelp/yelp_model/svm_small.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time dump(pipe_svm, \"/home/jupyter/data/yelp/yelp_model/svm_small.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1874912\n",
      "-rw-r--r-- 1 root root 522995808 Oct 26 13:45 logreg.joblib\n",
      "-rw-r--r-- 1 root root   7420344 Oct 26 13:51 logreg_small.joblib\n",
      "-rw-r--r-- 1 root root   7661465 Oct 26 13:45 model.joblib\n",
      "-rw-r--r-- 1 root root 839186606 Oct 26 13:45 nb.joblib\n",
      "-rw-r--r-- 1 root root  12203294 Oct 26 13:51 nb_small.joblib\n",
      "-rw-r--r-- 1 root root 522996092 Oct 26 13:45 svm.joblib\n",
      "-rw-r--r-- 1 root root   7420628 Oct 26 13:51 svm_small.joblib\n"
     ]
    }
   ],
   "source": [
    "!ls -l /home/jupyter/data/yelp/yelp_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil -m cp -n /home/jupyter/data/yelp/yelp_model/*.joblib gs://msca-bdp-data/yelp/yelp_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil -m cp -n /home/jupyter/data/yelp/yelp_model/*.joblib gs://msca-bdp-data-open/yelp/yelp_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wed, 26 October 2022 08:52:00'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "datetime.datetime.now(pytz.timezone('US/Central')).strftime(\"%a, %d %B %Y %H:%M:%S\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
