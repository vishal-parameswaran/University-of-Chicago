{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Class 3 Exercise 1:\n",
    "- Read tweets into Pandas Dataframe\n",
    "- Identify Bigrams and Trigrams for the top frequently mentioned AI / ML / NLP technologies\n",
    "\n",
    "**Suggestions:** \n",
    "- Eliminate URLs, Mentions, Hashtags, RTs and newline characters\n",
    "- Clean-up n-grams by eliminating punctuation, number, stopwords and lowercasing the text\n",
    "- Add custom stopwords filters to get more relevant results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('popular', halt_on_error=False)\n",
    "#nltk.download('all', halt_on_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk as nltk\n",
    "import nltk.corpus  \n",
    "from nltk.text import Text\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset records: 100043, Dataset columns: 7\n"
     ]
    }
   ],
   "source": [
    "url = 'https://storage.googleapis.com/msca-bdp-data-open/tweets/tweets_ai_ml_nlp.json'\n",
    "tweets = pd.read_json(url, orient='records', lines=True)\n",
    "\n",
    "print(f'Dataset records: {tweets.shape[0]}, Dataset columns: {tweets.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>extended_text</th>\n",
       "      <th>quoted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1529094548005064705</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>odol‚òòÔ∏è</td>\n",
       "      <td>RT @Frank4NC: CodyFight is a must watch and mu...</td>\n",
       "      <td>CodyFight is a must watch and must EARN! Get r...</td>\n",
       "      <td>Codyfight is a place where Humans and #AI comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1529094585942568960</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>Paijo s'Bejo</td>\n",
       "      <td>RT @Bakercrypt0: Wonderful day to everybody! ‚ú®...</td>\n",
       "      <td>Wonderful day to everybody! ‚ú®ü´∂\\n\\nThe trailer ...</td>\n",
       "      <td>Codyfight is a place where Humans and #AI comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1529094709771051013</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>üçÄGingüçÄ6Ô∏è‚É£5Ô∏è‚É£üéπ</td>\n",
       "      <td>RT @Frank4NC: CodyFight is a must watch and mu...</td>\n",
       "      <td>CodyFight is a must watch and must EARN! Get r...</td>\n",
       "      <td>Codyfight is a place where Humans and #AI comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1529094719120510976</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>Ultra mildüóØüí´</td>\n",
       "      <td>RT @codyfight: Codyfight is a place where Huma...</td>\n",
       "      <td>Codyfight is a place where Humans and #AI comp...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1529094845393907712</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>Ohayouüåº</td>\n",
       "      <td>RT @ninasimonic: Wonderful day to everybody! ‚ú®...</td>\n",
       "      <td>Wonderful day to everybody! ‚ú®ü´∂\\n\\nTheir traile...</td>\n",
       "      <td>Codyfight is a place where Humans and #AI comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id lang       date           name  \\\n",
       "0  1529094548005064705   en 2022-05-24         odol‚òòÔ∏è   \n",
       "1  1529094585942568960   en 2022-05-24   Paijo s'Bejo   \n",
       "2  1529094709771051013   en 2022-05-24  üçÄGingüçÄ6Ô∏è‚É£5Ô∏è‚É£üéπ   \n",
       "3  1529094719120510976   en 2022-05-24   Ultra mildüóØüí´   \n",
       "4  1529094845393907712   en 2022-05-24        Ohayouüåº   \n",
       "\n",
       "                                                text  \\\n",
       "0  RT @Frank4NC: CodyFight is a must watch and mu...   \n",
       "1  RT @Bakercrypt0: Wonderful day to everybody! ‚ú®...   \n",
       "2  RT @Frank4NC: CodyFight is a must watch and mu...   \n",
       "3  RT @codyfight: Codyfight is a place where Huma...   \n",
       "4  RT @ninasimonic: Wonderful day to everybody! ‚ú®...   \n",
       "\n",
       "                                       extended_text  \\\n",
       "0  CodyFight is a must watch and must EARN! Get r...   \n",
       "1  Wonderful day to everybody! ‚ú®ü´∂\\n\\nThe trailer ...   \n",
       "2  CodyFight is a must watch and must EARN! Get r...   \n",
       "3  Codyfight is a place where Humans and #AI comp...   \n",
       "4  Wonderful day to everybody! ‚ú®ü´∂\\n\\nTheir traile...   \n",
       "\n",
       "                                         quoted_text  \n",
       "0  Codyfight is a place where Humans and #AI comp...  \n",
       "1  Codyfight is a place where Humans and #AI comp...  \n",
       "2  Codyfight is a place where Humans and #AI comp...  \n",
       "3                                               None  \n",
       "4  Codyfight is a place where Humans and #AI comp...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use TweetTokenizer to tokenize Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_content(string):\n",
    "    url_pattern = r'(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])'\n",
    "    mention_pattern = r'[\\s]*@[\\w]+'\n",
    "    hashtag_pattern = r'[\\s]*#[\\w]+'\n",
    "    string_fixed = re.sub(url_pattern,\"\",string)\n",
    "    string_fixed = re.sub(hashtag_pattern,\"\",string_fixed)\n",
    "    string_fixed = re.sub(mention_pattern,\"\",string_fixed)\n",
    "    return string_fixed\n",
    "tweets[\"fixed_extended\"] = tweets[\"extended_text\"].apply(remove_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(machine, learning)</td>\n",
       "      <td>3280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(artificial, intelligence)</td>\n",
       "      <td>3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(data, science)</td>\n",
       "      <td>2032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(analytics, team)</td>\n",
       "      <td>1172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(insights, analytics)</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(deep, learning)</td>\n",
       "      <td>1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(big, data)</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(learning, python)</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(data, scientist)</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(data, analytics)</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(ai, ml)</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(learning, data)</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(data, analysis)</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(data, scientists)</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(python, programming)</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(learn, python)</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(using, python)</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(states, python)</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(intelligence, ai)</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(data, recovery)</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Word  Frequency\n",
       "0          (machine, learning)       3280\n",
       "1   (artificial, intelligence)       3069\n",
       "2              (data, science)       2032\n",
       "3            (analytics, team)       1172\n",
       "4        (insights, analytics)       1170\n",
       "5             (deep, learning)       1046\n",
       "6                  (big, data)        461\n",
       "7           (learning, python)        374\n",
       "8            (data, scientist)        351\n",
       "9            (data, analytics)        340\n",
       "10                    (ai, ml)        316\n",
       "11            (learning, data)        280\n",
       "12            (data, analysis)        243\n",
       "13          (data, scientists)        238\n",
       "14       (python, programming)        192\n",
       "15             (learn, python)        188\n",
       "16             (using, python)        188\n",
       "17            (states, python)        186\n",
       "18          (intelligence, ai)        184\n",
       "19            (data, recovery)        180"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text = tweets['fixed_extended'].str.lower().str.replace(r'\\|', ' ', regex=True).str.cat(sep=' ')\n",
    "tweet_tokenizer = nltk.tokenize.TweetTokenizer()\n",
    "words = tweet_tokenizer.tokenize(tweet_text)\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "words = [word for word in words if word.isalpha()]\n",
    "words = [word for word in words if not word.isnumeric()]\n",
    "words = [word.lower() for word in words]\n",
    "words = [word for word in words if word not in stopwords]\n",
    "bgs = nltk.bigrams(words)\n",
    "targeted_bgs = ['machine','learning','ai','artificial','intelligence','natural','language','processing','chatgpt','data','science','python','r','c','analytics','ml','nlp']\n",
    "bgs = [b for b in bgs if (b[0] in targeted_bgs) or (b[1] in targeted_bgs)]\n",
    "bigrams_freq = nltk.FreqDist(bgs)\n",
    "bigrams_freq_df = pd.DataFrame(bigrams_freq.most_common(),columns=['Word', 'Frequency'])\n",
    "bigrams_freq_df.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(insights, analytics, team)</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(analytics, team, using)</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(analytics, team, usafacts)</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(learning, data, science)</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(machine, learning, data)</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(deep, learning, python)</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(artificial, intelligence, ai)</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(trending, ai, ml)</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(ai, ml, article)</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(ml, article, identified)</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(data, science, deep)</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(science, deep, learning)</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(learning, python, complete)</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(python, complete, tutorial)</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(ai, machine, learning)</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(machine, learning, algorithms)</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(data, science, machine)</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(science, machine, learning)</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(natural, language, processing)</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(learn, data, science)</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Word  Frequency\n",
       "0       (insights, analytics, team)       1170\n",
       "1          (analytics, team, using)        668\n",
       "2       (analytics, team, usafacts)        502\n",
       "3         (learning, data, science)        235\n",
       "4         (machine, learning, data)        215\n",
       "5          (deep, learning, python)        203\n",
       "6    (artificial, intelligence, ai)        177\n",
       "7                (trending, ai, ml)        160\n",
       "8                 (ai, ml, article)        160\n",
       "9         (ml, article, identified)        160\n",
       "10            (data, science, deep)        156\n",
       "11        (science, deep, learning)        155\n",
       "12     (learning, python, complete)        146\n",
       "13     (python, complete, tutorial)        145\n",
       "14          (ai, machine, learning)        135\n",
       "15  (machine, learning, algorithms)        121\n",
       "16         (data, science, machine)        115\n",
       "17     (science, machine, learning)        115\n",
       "18  (natural, language, processing)        113\n",
       "19           (learn, data, science)        112"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text = tweets['fixed_extended'].str.lower().str.replace(r'\\|', ' ', regex=True).str.cat(sep=' ')\n",
    "tweet_tokenizer = nltk.tokenize.TweetTokenizer()\n",
    "words = tweet_tokenizer.tokenize(tweet_text)\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "words = [word for word in words if word.isalpha()]\n",
    "words = [word for word in words if not word.isnumeric()]\n",
    "words = [word.lower() for word in words]\n",
    "words = [word for word in words if word not in stopwords]\n",
    "bgs = nltk.trigrams(words)\n",
    "targeted_bgs = ['machine','learning','ai','artificial','intelligence','natural','language','processing','chatgpt','data','science','python','r','c','analytics','ml','nlp']\n",
    "bgs = [b for b in bgs if (b[0] in targeted_bgs) or (b[1] in targeted_bgs)]\n",
    "trigrams_dist = nltk.FreqDist(bgs)\n",
    "trigrams_dist_df = pd.DataFrame(trigrams_dist.most_common(),columns=['Word', 'Frequency'])\n",
    "trigrams_dist_df.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wed, 05 April 2023 20:21:53'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "datetime.datetime.now(pytz.timezone('US/Central')).strftime(\"%a, %d %B %Y %H:%M:%S\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "everything",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9d7a4ffad4f6b940f5e2789a62bdb58d1b41bd096fb341dd6a0cc7498e58b93c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
