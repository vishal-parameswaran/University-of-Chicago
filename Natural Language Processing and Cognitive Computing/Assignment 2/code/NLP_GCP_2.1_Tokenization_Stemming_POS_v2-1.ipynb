{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Class 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization, Stemming & Lemmatization, Part-of-speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers\\maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping misc\\mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping misc\\perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers\\porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers\\rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping help\\tagsets.zip.\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers\\universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\wordnet2022.zip.\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\yomaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('popular', halt_on_error=False)\n",
    "nltk.download('all', halt_on_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, sys\n",
    "import nltk as nltk\n",
    "import nltk.corpus  \n",
    "from nltk.text import Text\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Flu', 'season', 'hitting', 'earlier', ',', 'with', 'dozens', 'more', 'outbreaks', '—', 'and', 'more', 'severe', 'symptoms']\n"
     ]
    }
   ],
   "source": [
    "text = \"Flu season hitting earlier, with dozens more outbreaks — and more severe symptoms\"\n",
    "tokens = nltk.tokenize.word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy source data from GCS into local FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gcs_data (bucket_name, folder_name, file_name, local_folder_name):\n",
    "    url = 'https://storage.googleapis.com/' + bucket_name + '/' + folder_name + '/' + file_name\n",
    "    r = requests.get(url)\n",
    "    open(local_folder_name + '/' + file_name , 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: 3boat10.txt\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'msca-bdp-data-open'\n",
    "folder_name = 'books'\n",
    "file_name = ['3boat10.txt']\n",
    "local_folder_name = '/home/jupyter/data/books/'\n",
    "\n",
    "os.makedirs(local_folder_name, exist_ok=True)\n",
    "\n",
    "for file in file_name:\n",
    "    get_gcs_data (bucket_name = bucket_name,\n",
    "                 folder_name = folder_name,\n",
    "                 file_name = file,\n",
    "                 local_folder_name = local_folder_name)\n",
    "    print('Downloaded: ' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get most frequent words in a book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 7773 samples and 79641 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 5702),\n",
       " ('the', 3338),\n",
       " ('and', 3215),\n",
       " ('.', 3081),\n",
       " ('to', 1748),\n",
       " ('a', 1621),\n",
       " ('of', 1425),\n",
       " ('I', 1208),\n",
       " ('it', 1159),\n",
       " ('in', 931)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = local_folder_name + file_name[0]\n",
    "f = open(file_path)\n",
    "bk_3boat = f.read()\n",
    "\n",
    "words = nltk.tokenize.word_tokenize(bk_3boat)\n",
    "fdist = nltk.FreqDist(words)\n",
    "\n",
    "print(fdist)\n",
    "\n",
    "#fdist.items() - will give all words\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get most frequent clean words in a book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 6240 samples and 29842 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('said', 378),\n",
       " ('would', 362),\n",
       " ('harris', 316),\n",
       " ('george', 308),\n",
       " ('one', 246),\n",
       " ('us', 228),\n",
       " ('boat', 186),\n",
       " ('get', 179),\n",
       " ('could', 175),\n",
       " ('got', 163)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from nltk.corpus import stopwords\n",
    "\n",
    "#default_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "words = nltk.tokenize.word_tokenize(bk_3boat)\n",
    "\n",
    "#stopwords = stopwords.words('english')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Remove single-character tokens (mostly punctuation)\n",
    "words = [word for word in words if len(word) > 1]\n",
    "\n",
    "# Remove numbers\n",
    "#words = [word for word in words if not word.isnumeric()]\n",
    "\n",
    "# Remove punctuation\n",
    "words = [word for word in words if word.isalpha()]\n",
    "\n",
    "# Lowercase all words (default_stopwords are lowercase too)\n",
    "words_lc = [word.lower() for word in words]\n",
    "\n",
    "# Remove stopwords\n",
    "words_lc = [word for word in words_lc if word not in stopwords]\n",
    "\n",
    "# Remove stopwords\n",
    "# words = [word for word in words if word not in stopwords]\n",
    "\n",
    "\n",
    "fdist = nltk.FreqDist(words_lc)\n",
    "\n",
    "print(fdist)\n",
    "\n",
    "#fdist.items() - will give all words\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have to instantiate a Text object first, and then call it on that object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "textList = Text(nltk.corpus.gutenberg.words(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A concordance view shows us every occurrence of a given word, together with some context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 199 matches:\n",
      "THREE MEN IN A BOAT ( TO SAY NOTHING OF THE DOG ). Three\n",
      "NOTHING OF THE DOG ). Three Men in a Boat by Jerome K . Jerome CHAPTER I . THR\n",
      "ty of people very bad indeed , whole boat - loads of them ; but I never met a \n",
      " like a fellow I saw on the Yarmouth boat one day , I could account for the se\n",
      "ckles I ever tasted in a respectable boat . Did you have any ?\" For myself , I\n",
      "eep , you get fooling about with the boat , and slop me overboard . If you ask\n",
      "o down in the morning , and take the boat up to Chertsey , and George , who wo\n",
      "n stillness . Then we run our little boat into some quiet nook , and the tent \n",
      "talk , the river , playing round the boat , prattles strange old tales and sec\n",
      "is a good two inches of water in the boat , and all the things are damp . You \n",
      "rd man , who has been baling out the boat , and who has spilled the water down\n",
      "uld not allow of the navigation of a boat sufficiently large to take the thing\n",
      "eople , on that voyage , load up the boat till it is ever in danger of swampin\n",
      " ! Throw it overboard . It makes the boat so heavy to pull , you nearly faint \n",
      "row the lumber over , man ! Let your boat of life be light , packed with only \n",
      " dangerous thing . You will find the boat easier to pull then , and it will no\n",
      " suggested George ; \" we will have a boat with a cover . It is ever so much si\n",
      "ean . You fix iron hoops up over the boat , and stretch a huge canvas over the\n",
      " stem to stern , and it converts the boat into a sort of little house , and it\n",
      "it was so pleasant to wake up in the boat in the fresh morning , and plunge in\n",
      "ave Harris clean and fresh about the boat , even if we did have to take a few \n",
      "ooze . We kept it in the nose of the boat , and , from there , it oozed down t\n",
      " the rudder , impregnating the whole boat and everything in it on its way , an\n",
      "away from it at Marlow . We left the boat by the bridge , and took a walk thro\n",
      "r to take paraffine oil with us in a boat again - except , of course , in case\n"
     ]
    }
   ],
   "source": [
    "textList.concordance(\"boat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 88 matches:\n",
      " thin , not the captain ) and soda - water ; but , towards Saturday , he got up\n",
      "night ,\" and , lulled by the lapping water and the rustling trees , we fall asl\n",
      " , and there is a good two inches of water in the boat , and all the things are\n",
      "t the boat , and who has spilled the water down his sleeve , and has been cursi\n",
      " good , plain merchandise will stand water . You will have time to think as wel\n",
      "hen they are going anywhere near the water , but that they don ' t bathe much w\n",
      " , shivering , through six inches of water . And when I do get to the sea , it \n",
      " swimming for my life in two feet of water . I hop back and dress , and crawl h\n",
      "of Harris ' s , which you mixed with water and called lemonade , plenty of tea \n",
      "orted . \" Now we shan ' t get on the water till after twelve . I wonder you tak\n",
      "on , and prognosticate drought , and water famine , and sunstroke , and simooms\n",
      "the lower part of the town was under water , owing to the river having overflow\n",
      "ident he was the 9 . 32 for Virginia Water , or the 10 a . m . express for the \n",
      "ngston , where they came down to the water ' s edge , looked quite picturesque \n",
      " cloaked gallants swaggered down the water - steps to cry : \" What Ferry , ho !\n",
      "metimes , when you could not see any water at all , but only a brilliant tangle\n",
      "easant landscape , and the sparkling water , it is one of the gayest sights I k\n",
      "t was my misfortune once to go for a water picnic with two ladies of this kind \n",
      "anywhere near real earth , air , and water . The first thing was that they thou\n",
      "ing , and it appeared that a drop of water ruined those costumes . The mark nev\n",
      "m , and I picked out a smooth bit of water to drop them into again each time . \n",
      "ld not help an occasional flicker of water from going over those dresses . The \n",
      "e . When he spread more than pint of water over one of those dresses , he would\n",
      ", and sloush the things about in the water .\" The elder sister said that she wa\n",
      "n the hamper , and a gallon - jar of water in the nose of the boat , and that t\n"
     ]
    }
   ],
   "source": [
    "textList.concordance(\"water\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 31 matches:\n",
      "MEN IN A BOAT ( TO SAY NOTHING OF THE DOG ). Three Men in a Boat by Jerome K . \n",
      "ed up at me , and think : \" Oh , that dog will never live . He will be snatched\n",
      "t door but one for having a ferocious dog at large , that had kept him pinned u\n",
      "e and someone to love you , a cat , a dog , and a pipe or two , enough to eat a\n",
      "ed him . I didn ' t encourage him . A dog like that don ' t want any encouragem\n",
      " with eggs and bacon , irritating the dog , or flirting with the slavey , inste\n",
      "dly . He would take bronchitis in the dog - days , and have hay - fever at Chri\n",
      "by the lady of the house ? That china dog that ornaments the bedroom of my furn\n",
      "my furnished lodgings . It is a white dog . Its eyes blue . Its nose is a delic\n",
      "me it is more than probable that that dog will be dug up from somewhere or othe\n",
      "s age , do not see the beauty of that dog . We are too familiar with it . It is\n",
      "o our eyes . So it is with that china dog . In 2288 people will gush over it . \n",
      " one another , and we beamed upon the dog , too . We loved each other , we love\n",
      "INE TO DRINK THE RIVER . - A PEACEFUL DOG . - STRANGE DISAPPEARANCE OF HARRIS A\n",
      "life , with care . I do not blame the dog ( contenting myself , as a rule , wit\n",
      "but mangy about the middle ; a bull - dog , a few Lowther Arcade sort of animal\n",
      "chained up there , between the bull - dog and the poodle . He sat and looked ab\n",
      "d dignified . He looked at the bull - dog , sleeping dreamlessly on his right .\n",
      "his own place , and caught the bull - dog by the ear , and tried to throw him a\n",
      "ed to throw him away ; and the bull - dog , a curiously impartial animal , went\n",
      "d , and snatched up that sweet little dog of hers ( he had laid the tyke up for\n",
      "have chilled the heart of the boldest dog . He stopped abruptly , and looked ba\n",
      "' s boy , with basket . Long - haired dog . Cheesemonger ' s boy , with basket \n",
      "owards us on the sluggish current , a dog . It was one of the quietest and peac\n",
      "dogs I have ever seen . I never met a dog who seemed more contented - more easy\n"
     ]
    }
   ],
   "source": [
    "textList.concordance(\"dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using \"similar\" helps us discover what other words appear in a similar range of contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "river man thing time water night day bank lock way morning things boy\n",
      "room matter world air city business kettle\n"
     ]
    }
   ],
   "source": [
    "textList.similar(\"boat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "river boat thing time room bank morning night man things sea lock it\n",
      "other way place house subject them matter\n"
     ]
    }
   ],
   "source": [
    "textList.similar(\"water\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bit man long morning change dream body widow party trout boat harris\n",
      "hundred rest week river mean he out is\n"
     ]
    }
   ],
   "source": [
    "textList.similar(\"dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positional information helps determine the location of a word in the text: how many words from the beginning it appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAHHCAYAAABKudlQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBiUlEQVR4nO3deXgV1eH/8c8NSW72hC2BQBLWAEE2QSKyC0gtxaWLS1EBpS7FoqJYESuLC2jrQrVarF/Bn0tVVKRu7AEFEUEIuxAgArIkQMhGIAnJ+f1BM83NRgIJ4cT363nuY+7MuXPOmTkz9+PcmcFljDECAACwlFdtNwAAAOB8EGYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZoA6YMqUKXK5XDW2/FGjRqlFixY1suwWLVpo1KhRNbLsC+XHH3+Uy+XSnDlzarsp5arpMQLUJsIMUM3mzJkjl8uldevW1XZTLrgBAwbI5XLJ5XLJy8tLISEhateunW699VYtXry4tptXJ40aNcpZ5y6XSyEhIerSpYuee+455ebmVksdr7zyykUd1ADv2m4AgPP32GOP6ZFHHqntZkiSmjdvrunTp0uSTpw4oV27dunjjz/W22+/rRtuuEFvv/22fHx8nPI7duyQl5fd/18VExOjkydPevTrQnK73Xr99dclSenp6froo4/00EMPae3atXrvvffOe/mvvPKKGjVqZP0ZNNRdhBmgDvD29pa398WxO4eGhuqWW27xmDZjxgyNGzdOr7zyilq0aKFnnnnGmed2uy90EyvFGKNTp07J39//rGVdLpf8/PwuQKvK5u3t7bHO//jHPyo+Pl7vv/++nn/+eUVGRtZa24ALwe7/HQIsduDAAd1+++2KiIiQ2+1Wx44d9cYbbzjzT548qfbt26t9+/Y6efKkMz0tLU1NmzbVFVdcoYKCAknlXw/x9ttvq2fPngoICFD9+vXVr18/LVq0yJk/f/58DRs2TJGRkXK73WrdurWeeOIJZ7nVpV69evr73/+uuLg4vfzyy8rIyHDmlbxmJj8/X1OnTlXbtm3l5+enhg0bqk+fPh4/U40aNUpBQUHas2ePhg4dqsDAQEVGRmratGkyxnjUXVhYqBdffFEdO3aUn5+fIiIidNddd+n48eMe5Vq0aKFf/epXWrhwoXr06CF/f3/NmjVLkrR48WL16dNHYWFhCgoKUrt27fToo486ny3vmplly5apb9++CgwMVFhYmK699lpt377do0zRttu1a5dGjRqlsLAwhYaGavTo0crJyTmn9e3l5aUBAwY4bSvP6dOn9cQTT6h169Zyu91q0aKFHn30UY+fp1q0aKGtW7dqxYoVzk9ZRcsGLhaEGaAWpKSk6PLLL9eSJUt07733aubMmWrTpo3uuOMOvfjii5Ikf39/vfnmm9q1a5cmTZrkfHbs2LHKyMjQnDlzVK9evXLrmDp1qm699Vb5+Pho2rRpmjp1qqKiorRs2TKnzJw5cxQUFKTx48dr5syZ6t69ux5//PEa+cmqXr16uvnmm5WTk6OVK1eWW27KlCmaOnWqBg4cqJdfflmTJk1SdHS01q9f71GuoKBAv/jFLxQREaFnn31W3bt31+TJkzV58mSPcnfddZcmTJig3r17a+bMmRo9erTeeecdDR06VPn5+R5ld+zYoZtvvllDhgzRzJkz1bVrV23dulW/+tWvlJubq2nTpum5557TNddco1WrVlXY3yVLlmjo0KFKTU3VlClTNH78eH3zzTfq3bt3mQHjhhtuUFZWlqZPn64bbrhBc+bM0dSpU8+yVsu3e/duSVLDhg3LLTNmzBg9/vjjuvTSS/XCCy+of//+mj59um666SanzIsvvqjmzZurffv2euutt/TWW295jEfgomAAVKvZs2cbSWbt2rXllrnjjjtM06ZNzdGjRz2m33TTTSY0NNTk5OQ40yZOnGi8vLzMV199ZebOnWskmRdffNHjc5MnTzbFd+ekpCTj5eVlrr/+elNQUOBRtrCw0Pm7eD1F7rrrLhMQEGBOnTrlTBs5cqSJiYmpuOPGmP79+5uOHTuWO3/evHlGkpk5c6YzLSYmxowcOdJ536VLFzNs2LAK6xk5cqSRZP70pz850woLC82wYcOMr6+vOXLkiDHGmK+//tpIMu+8847H5xcsWFBqekxMjJFkFixY4FH2hRdeMJKcZZYlOTnZSDKzZ892pnXt2tWEh4ebY8eOOdM2btxovLy8zG233eZMK9p2t99+u8cyr7/+etOwYcMK10PRuggMDDRHjhwxR44cMbt27TJPP/20cblcpnPnzqXqKZKYmGgkmTFjxngs76GHHjKSzLJly5xpHTt2NP379z9rW4DawpkZ4AIzxuijjz7S8OHDZYzR0aNHndfQoUOVkZHhcRZiypQp6tixo0aOHKk//vGP6t+/v8aNG1dhHZ988okKCwv1+OOPl7q4tvjPUcWvB8nKytLRo0fVt29f5eTk6IcffqimHv9PUFCQU1d5wsLCtHXrViUlJZ11effee6/zt8vl0r333qu8vDwtWbJEkjR37lyFhoZqyJAhHuu5e/fuCgoKUkJCgsfyWrZsqaFDh5Zqj3TmJ7nCwsJK9fPQoUNKTEzUqFGj1KBBA2d6586dNWTIEH3xxRelPnP33Xd7vO/bt6+OHTumzMzMs9Z34sQJNW7cWI0bN1abNm306KOPqlevXpo3b165nylqw/jx4z2mP/jgg5Kkzz///Kz1AhcLwgxwgR05ckTp6el67bXXnC+gotfo0aMlSampqU55X19fvfHGG0pOTlZWVpZmz5591ueF7N69W15eXoqLi6uw3NatW3X99dcrNDRUISEhaty4sXMhafHrWqpLdna2JCk4OLjcMtOmTVN6erpiY2PVqVMnTZgwQZs2bSpVzsvLS61atfKYFhsbK+l/14kkJSUpIyND4eHhpdZ1dna2x3qWzoSZkm688Ub17t1bY8aMUUREhG666SZ98MEHFQabvXv3SpLatWtXal6HDh109OhRnThxwmN6dHS0x/v69etLUqlre8ri5+enxYsXa/Hixfrqq6+0f/9+rVq1qtT6KdlGLy8vtWnTxmN6kyZNFBYW5vQBsMHFcfsD8DNS9CV4yy23aOTIkWWW6dy5s8f7hQsXSpJOnTqlpKSkMr90qyo9PV39+/dXSEiIpk2bptatW8vPz0/r16/Xn//850qfhaiKLVu2SFKpL9Di+vXrp927d2v+/PlatGiRXn/9db3wwgv65z//qTFjxlSpvsLCQoWHh+udd94pc37jxo093pd155K/v7+++uorJSQk6PPPP9eCBQv0/vvv68orr9SiRYsqvG6pKspbjilxQXN5nx08ePA51cuD9FAXEGaAC6xx48YKDg5WQUFBpb6ANm3apGnTpmn06NFKTEzUmDFjtHnzZoWGhpb7mdatW6uwsFDbtm1T165dyyyzfPlyHTt2TB9//LH69evnTE9OTq5ynyqjoKBA7777rgICAtSnT58KyzZo0ECjR4/W6NGjlZ2drX79+mnKlCkeYaawsFB79uxxzsZI0s6dOyXJeVpx69attWTJEvXu3btSt1iXx8vLS4MGDdKgQYP0/PPP6+mnn9akSZOUkJBQ5jaMiYmRdOaC4pJ++OEHNWrUSIGBgefcnuoQExOjwsJCJSUlqUOHDs70lJQUpaenO32QCDy4+PEzE3CB1atXT7/5zW/00UcfOWcqijty5Ijzd35+vkaNGqXIyEjNnDlTc+bMUUpKih544IEK67juuuvk5eWladOmlTrDUvR/+kVnAor/n39eXp5eeeWVc+5beQoKCjRu3Dht375d48aNU0hISLlljx075vE+KChIbdq0KfNpti+//LLztzFGL7/8snx8fDRo0CBJZ+4QKigo0BNPPFHqs6dPn1Z6evpZ256WllZqWlFALO8Ju02bNlXXrl315ptvetSxZcsWLVq0SL/85S/PWm9NK2pD0d1zRZ5//nlJ0rBhw5xpgYGBlVpXQG3hzAxQQ9544w0tWLCg1PT77rtPM2bMUEJCguLj4/WHP/xBcXFxSktL0/r167VkyRLnC/TJJ59UYmKili5dquDgYHXu3FmPP/64HnvsMf32t78t90uxTZs2mjRpkp544gn17dtXv/71r+V2u7V27VpFRkZq+vTpuuKKK1S/fn2NHDlS48aNk8vl0ltvvVWpnzUqkpGRobfffluSlJOT4zwBePfu3brpppvKDBbFxcXFacCAAerevbsaNGigdevW6cMPP/S42Fc6c53IggULNHLkSMXHx+vLL7/U559/rkcffdT5+ah///666667NH36dCUmJuqqq66Sj4+PkpKSNHfuXM2cOVO//e1vK2zPtGnT9NVXX2nYsGGKiYlRamqqXnnlFTVv3rzCM0x//etfdfXVV6tXr1664447dPLkSb300ksKDQ3VlClTKrEma1aXLl00cuRIvfbaa85Pjt99953efPNNXXfddRo4cKBTtnv37nr11Vf15JNPqk2bNgoPD9eVV15Zi60HSqjFO6mAOqno1uzyXvv37zfGGJOSkmLGjh1roqKijI+Pj2nSpIkZNGiQee2114wxxnz//ffG29vb4/ZjY4w5ffq0ueyyy0xkZKQ5fvy4Mab0bbdF3njjDdOtWzfjdrtN/fr1Tf/+/c3ixYud+atWrTKXX3658ff3N5GRkebhhx82CxcuNJJMQkKCU64qt2YX72tQUJBp27atueWWW8yiRYvK/EzJW7OffPJJ07NnTxMWFmb8/f1N+/btzVNPPWXy8vI82hMYGGh2795trrrqKhMQEGAiIiLM5MmTS92Kbowxr732munevbvx9/c3wcHBplOnTubhhx82Bw8e9GhHWbeEL1261Fx77bUmMjLS+Pr6msjISHPzzTebnTt3OmXKujXbGGOWLFlievfubfz9/U1ISIgZPny42bZtm0eZom1X8tbvonGUnJxc5noruS7Opqwxkp+fb6ZOnWpatmxpfHx8TFRUlJk4caLHbfnGGHP48GEzbNgwExwcbCRxmzYuOi5jzvN/wwDgAhs1apQ+/PBD5+4oAD9vXDMDAACsRpgBAABWI8wAAACrcc0MAACwGmdmAACA1QgzAADAanX+oXmFhYU6ePCggoODeSQ3AACWMMYoKytLkZGR8vKq+NxLnQ8zBw8eVFRUVG03AwAAnIP9+/erefPmFZap82EmODhY0pmVUdG/BwMAAC4emZmZioqKcr7HK1Lnw0zRT0shISGEGQAALFOZS0S4ABgAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsVqUwc+Os1Zr66daaakut1wcAAOzjXdsNsNm2gxma+uk2/enKNlr743GNiI+WJL321R4dy87Vj8dy9NT1lyguMlSSlJp5Su+s2aehHSO0cGuKRsRHKzzE75zqTs085dSTlJqtxkG+2n44S3/7XRf1advYmS9Jd/ZrpZ0pWXpo7kZ1iw5Ts7AA3dmv1TnXfSEUrauidVTyfXUuuzxF23fy8DhnG3668YAe+WiT+sU21tRrLpGkSrer+PZ/+9u92n4oy2N8VKeS279k20qOxaI2rdp1VKmZp9Qtpr72HDmhw5m5igj2lXc9L6Vl56pbTH0dy87T6YJCSZK/r7ee/W3nMvtQvI6P1x9w9okHr4rV8h1HlJN3WgG+3vr1pc089oeyts+2gxmaNG+LWjQMUMMg9zmN35L7TOfmobrl8pgq74vVORaLL/PFJTv1/d7j8qnnpUeubu+sI0nOeio5bqraluLlpTPHqqI6iuopvm7Pt6+VHYeXtaivl5btcva11MxTmv7Fdq3cdVQ9WtRX/QBfj7YV/9wTn21T2ok8vXBjV/Vp29hZ9raDGXrg/UQdycpVfKsGkpHW7T2uS5qFKD3ndKX2vZL77Pd7j0uS4pqGeIzDstZTTYyTon4V/965rEV9Pbdopzo0Ddb9g2MlqdT3TNG0ovX8pyvbaPmOI9p2MEPf7klTsL+3bomP1hurktUsLEB/v7mbsx2KxkjR+i9aVtFyX1yyU5t+ylDn5qG6f3BsrX2vEGbOw86UbK1JTlOffemauTRJQ+IiJEmvr0z2KOOEmaxczVyapJaNAp3y5xxmsnI96imyYV/6mTBTbP513Zppw750Hc7M1ZdbUpxpF3WY+e+6KlpHJd9X57LLU7R9i2/DNXvSdCKvUF9uSdHYgW0lqdLtKr793/1uv1NHjYSZEtu/1JdIibFYvE2S9M3uNOfvlKy8MqcXKa8PxesoPlY37Ev3eH9Js9CzbuudKdnasD9dG/anl9unsym5z2w5mKmeLRtWeVxV51gsvszi67/kOpLOrKeS46aqbSleXlKZx5Di6/Z8+1rZcfjgkFiPfS01K1fzEg9KknPMKr6M4p/bkZIt6X/HviI7U7KdecWXkbDjqDP/rGGmjH1WkrPcku0pvp5qYpwUtbv4986DQ2KdfeP38TGSVOp7pmha0XruU2J8ZZw8ra93HdPJfKNdR054bIfi5a7r1sxZVtFyi9bLloOZ+n18TK19r5zzNTMtHvlcC7ce9pjWacpCzV13pmP703LU4pHPtWDLId302mq1/8uX+sWLXznJtsi6H9N046wz8ztPWahb/2+NMnLynfnGSNO/2K4uUxepx5NL9MLinefaZAAAUAfV+AXAf124Q3f2a6UvxvVVq8aBGvfvDc4p6q0HM/T719eobUSQPr6ntz685woN7hChAmOcz3/0/U/y962nT8b21sSr2+vvy5L0ddKRcuvLzc1VZmamxwsAANRdNR5m7uzXSle2j1CrxkF6YHCsDqSf1I/HciRJs1bsUedmoXryuk6KiwxRbESwRl7RQg0CfZ3Pt//v74AtGwXqN92bq3OzUK3adazc+qZPn67Q0FDnFRUVVdNdBAAAtajGw0z7JiHO3+HBZ35LO5adK0nadihTV7RpVOnPS1LjYD/n82WZOHGiMjIynNf+/fvLLQsAAOx3zhcAu1xnrmcp7nSBKVXOu56r2IfO/Kfwv8X8fM6epTw+/996C0tX43C73XK73WddLgAAqBvO+cxMw0BfHck65bxPPnpCJ/MLqrSM9k1C9M2uo+faBAAAgHM/M9OrdSO9uXqvukXXV6ExmvHlD/IpcRblbP44oLV+8eLXeuyTzRoRHyOfel5aveeYhnVq6nHdzMUqNiJI8S0bqFt0mO4b1FbhwWfOCI3p09J5pkZsRJBTPjzYrfsGtVVsRJBH+XMRHux26in+nJlu0WEe84v+7hYdpiYhbuc5M+dT94VQtK6K2lnyfXUuuzxF27f4Noxv1UDzNvykfrGNnc9Xtl3Ft//ve0Zp+6Esj2VXp5Lbv6K2FG/TuTxnprw+FK+j+D7RLTpMY/q0dJ5dUXJ/KGv7xEYEqVtUmPOcmXMZByX3mc7NQ89pX6zOsVh8mb/vGeU8Z6b4OpLkrKeS46aqbSlZvngdRfUUX9b59rWy47BbdJjHvhYe7Nb1XSNLPWem5BjpFh2mdhFBSjuR5xz7isRGBKldRFC5z5mpzL5Xcp8t+ZyZisZsTYyTon4V/97pFh2mblFh6tA02OOYVHJsF1/PReOr+HNm+rZpqKSUTDULC/DYDsX31bKOeb/vGeU8Z6Y2v1dcxpT8sah8N85arbjIEE0e3lEpmaf00NyN+n7vcUWE+Onx4XEa9+8NevxXcfpdjyjtT8tR32cT9Pm4Pur433v5M07mq8vURfr3Hy5Xr9YNJUnf7jmmvy7coc0HMuTn7aWu0fX10s3dFOrv41FfkT/8v3UK8fPRczd0qVSbMzMzFRoaqoyMDIWEhJz9AwAAoNZV5fu7SmHGRoQZAADsU5Xvb/6hSQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACr1ViYafHI51q49XBNLR4AAEBSDYaZ7yYN0oB2jWtq8XXOtoMZunHWam07mFHlz6ZmntILi3cqNfNUDbTs3NpQm20qWfe2gxka+sIKXfbkYq1MOnLB24OquRjGs61SM0/p0Y83adDfEnTZk4v16cYDemHxTm07mFHl/XNl0hH1nrH0vPYZtmXlneu6utDr+GI61hdXI2Em73ShwoP95PauVxOLlyQVFBoVFpoaW/6FtjMlW2uS07QzJbvKn03NytXMpUlKzcqtgZadWxtqs00l696Zkq0dKdk6kp2nDfvSL3h7UDUXw3i2VWpWrt79br92H83Rkew8rdmTpplLk7QzJbvK++eGfek6kH7qvPYZtmXlneu6utDr+GI61hfnXR0LuXHWarVrEqx6Xi59suGA2jUJ1rd70jTr1u4a2rGJfv3KKl3WsoEmXt3B+cyx7FzFP71U74yJV3yrhso9XaC/Ldyh/2w8qMyTpxXbJFiP/KK9erVuKEmau26/pn22Tc/f0FXPLPhByUdPaPlDAxTVIKA6ugAAACxVbWdmPvr+J/nW89KH91yhp67v5DHvum7N9NnGQzLmf2dSPtt0SBEhfurZsoEkafL8rVq/L10v3XypFtzfV8M6NdHI2d8p+egJ5zOn8gv0zxW79cxvOmnRA/3UKMhdqh25ubnKzMz0eAEAgLqr2sJMi0aBmvjLDmrdOEitGwd5zBvWqalSMk9p7Y/HnWnzEw9oeJdIuVwuHUg/qbnf/6RXRlyqni0bKKZhoO7s11qXtaivuev2O5/JLzB64tpL1D2mgVo3DpK/b+mfsaZPn67Q0FDnFRUVVV1dBAAAF6Fq+ZlJkjo1Cy13XsMgt/q2baRPEg+oZ8sG2p+Wo/X70vX0r8+cwdlxOFMFhUYD/7bc43N5pwsVFuDrvPet56UOTYMrbMfEiRM1fvx4531mZiaBBgCAOqzawkxZZ0mKu65bM035z1ZNvaaj5iceUPsmwWrfJESSdCK3QPW8XPr0T31Uz+Xy+FyA+3/Ldft4yVVifklut1tud+mfnwAAQN10wR6aNyQuQrmnC7VixxHNTzyoa7s2c+Z1jAxRQaHRsew8tWgU6PEKD/a7UE0EAAAWqrYzM2cT4Outq+Ii9Nzindp1JFvXdI105rVqHKTrukZq/AeJemxYB3WMDNWxE3lateuoOjQN1pXtIy5UM2tNbESQ4ls2UGxE0NkLlxAe7NZ9g9oqPLj2zkiVbENttqlk3bERQWoXEaS0E3nqFh12wduDqrkYxrOtwoPd+n3PKK3Zc0yZp04rvlUDNQxyKzYiqMr7Z7foMDUL8zuvfYZtWXnnuq4u9Dq+mI71xblM8VuMztGNs1YrLjJEk4d3dKa1eORz59bsIgk7UjV69lr1bNlAH9zVy2MZ+QWFemnZLn28/ielZJ5S/QBfdYsO0wNDYtW+SYhza/bmKUOr1LbMzEyFhoYqIyNDISEh59dRAABwQVTl+7tawszFjDADAIB9qvL9zT80CQAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGC1Cx5mbpy1WlM/3XqhqwUAAHWUd203oK5IzTylF5fs1PZDWXrq+kskSVM/3abJw+MUFxlaI/W9s2afRsRHKzzEr9z2bPopQ52bh+qWy2O0cGtKueXPpY6abH95n3ntqz2SpF9f2kwfrz8gSbqzX6sqtW9l0hH9+aNNeuY3ndWnbeOz1peTd1oBvt5OPRW1vTLz2oQHasaXPzj1F+9XVftSXruL6nnq8+3qFh0mGWnD/nRNGtZBG/dneNRVvM2SqrRdSm6ThVtTNLRjhMdYK2+d1OT4qqi9Z9tvSq6Lkv2pyLaDGXr4w02SpGd/2/mc9/2VSUf0wPuJahjkq8eGxWntj8c91mfRuJSkAF9vdYkK9RhTFSnq49COEXr7273afihLD14Vq+U7jkg6sx3/9dUerd5zTH/7XRc1CPTVpHlb1KFpsO4fHOuxTYuPsWZhAeWO38qs95LjqLLjYtvBDE39dJv+dGUbj/W07WBGue0ub9lFy6rouF1yfz2anevxmdTMU5r+xXat2HlEAb71lJNXoP7tGmvi1R0qHP/lHW/KqvvA8Rxt2J+uv/2uS6ntXXzs3HJ5jF5dvlv3DGitTzce0i2XR2vWijNtf/a3nbV+33FNmb9VzRsE6JURl6pRkLvU2LqzXytJnseF4utJqtnvusriZ6ZqkpqVq3e/268N+9O1MyVbO1OytSY5TTtTsmusvplLk5SalVthe7YczNS73+3XzpTsCsufSx3n41yWnZqVq9dXJuv1lcnamZLt/F3V9m3Yl64D6ae0YV96pep797v9HvVU1PbKzFuzJ82j/uL9qo51Xbyew5m5+nJLir7cmqLDmblasyetVF3F21zV7VJym8xcmlRqrJW3zJocXxW192z7Tcl1UZV9Z2dKtrYczNSWg5nnte9v2JeuI9l5+uFwtjbsSy+1PovGZdHYLDmmKlK8X0XHrA370j2247zEgzqcmasN+84czzbsT9e73+0vtU2Lj7GKxm9l1nvJcVTZcVF0rC25nipqd3nLrsxxu+T+WvIzqVm5mpd4UGk5+fop/ZTScvI1b8PBs47/8o43ZdVdtD+Xtb2Lj51Vu47pQPoprdp1TGuS07RmT5rH+Fy165hOG+nHYznamZJd5tgq67hQvM81/V1XWTV6ZiYn77Qem7dFC7YeVqDbW3f2beUxPyMnX1M/3aol21OUV1Co+JYNNeWajmrZKNAp8+/v9unvS5N0PCdP/do2Vs+WDTRzaZI2Txlak00HAACWqNEzM09/sV1rktP0r9t66K07eurbPce09WCmM//BuRu16UCGXh95mT6+p7eMpNGzv1N+QaEkad2PaZo0b7NG926hL8b1Vd+2jfRywq4K68zNzVVmZqbHCwAA1F01FmZO5J7WB2t/0qO/7KDebRqpfZMQPXdDF50uPBNUko+e0JLtKXrmN53Us2UDxUWGaOaNXXU485QWbU2RJM355kcNaBeuO/u1VqvGQbq1VwsNiK349+Dp06crNDTUeUVFRdVUFwEAwEWgxsLM3mM5yisoVNfoMGdaWICvWjUKkiTtSs2Wt5dLXaPqO/PrB56Zvyv1zG9ve46cUJfmYcUXqy5Rnu9LmjhxojIyMpzX/v37q6U/AADg4lTn7mZyu91yu9213QwAAHCB1NiZmZiGAfKp51JisautM3LylXz0hCSpTXiQThcaJe4/7sw/fiJPe45mq23EmbM3rRoHatNP6cUXq00/ZdRUkwEAgIVq7MxMoNtbN/SI0tNfbFf9AB81DHLrrwt3yMt1Zn7LRoEaEhehRz7arKd/3UmBvt56ZsEPahLipyFxEZKkUVe00A2zVuv1r/doUIcIfbP7qJbvSJWrphp9HsKD3fp9zyhtP5Sl2P+GsfiWDZy/a6K++wa1VXhw2WehitpT9JyZ2IigCsufSx3n41yWHR7s1pg+LSVJsRFBzt9Vbd+ZZ2L4nXn+SiXqK3ruQ1E9FbW9MvPahAcqYUeqU3/xflXHui5ez5LtKR7PmYlv1UB+PvU86irZ5qpsl5Lb5L5BbUuNtfLWSU2Or4rae7b9puS6qMq+ExsRpEsiQ5y/z1W36DA1DvJVwyBfdYsOK7U+i8al9L/nzBQfUxUp6mNsRJBzzOoWHeaxHa/vGqnVe46pW3SYGgT6qltUmDo0DS61TYuPsWZhAZVer2XNLzmOKjsuYiOCFN+yQan1FBsRVG67y1t20bIq2nYl91cvl+exPjzYreu7RpZ6zszZxn95x5uy6i56zkxZ27v42OndpqE2/ZSu3m0aKu1EnuJbNVDi/nSnr9m5DbV462E1bxCg2IggNQoqPbbKOi6UXE81+V1XWS5jjKmphZ/IPa3HPtmiBVvO3Jr9h74tteyHVMVFhmjy8I7OrdmLt6cov6BQPVs21NQybs2euSRJ6SfP3JrduXmo3ly9V2snDa5UGzIzMxUaGqqMjAyFhITUVFcBAEA1qsr3d42GmZrwyEebtPtItubefUWlyhNmAACwT1W+vy/6JwC/9tVubTuYqR+PntCcVcn6aP1P+s2lzWu7WQAA4CJx0d/NtHF/hmat2KPs3NOKbhCgycM76qae0bXdLAAAcJG46MPMP0ZcWttNAAAAF7GL/mcmAACAihBmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBq1RZmbpy1WlM/3VpdiwMAAKgUq87MEJjOX2rmKb2weKdSM0/VdlMuGuezTlifOB82jJ+y2mhDu3H+bNrOVoUZnL/UrFzNXJqk1Kzc2m7KReN81gnrE+fDhvFTVhttaDfOn03b2bs6F1ZQaPT4/C2at/6AvOu5dMvlMRo/JFYul0sZOfma+ulWLdmeoryCQsW3bKgp13RUy0aBkqTjJ/L0+H+26rvkY8o4ma+YBoH648DWurZrM0nSgx9s1JrkNK1JTtPsVT9Kkr5+eKCiGgRUZxcAAIBlqjXMfPT9T7rhsih9cm9vbf4pQxM/3qzIMH/d3DNaD87dqB+PndDrIy9TkNtbMxb8oNGzv9Pi8f3lU89LuacL1alZiO7u30rBbh8t+yFF4z/YqJiGgeoaFabJ18Qp+Wi22jUJ1gNDYiVJDQPdpdqQm5ur3Nz/pcjMzMzq7CIAALjIVOvPTE3D/PX4r+LUunGQruvWTCOvaKH/W5ms5KMntGR7ip75TSf1bNlAcZEhmnljVx3OPKVFW1MkSU1C/XRnv9bqGBmq6IYBGtW7pfrHNtbnmw5KkkL8fORTz0t+PvUUHuyn8GA/1fNylWrD9OnTFRoa6ryioqKqs4sAAOAiU61nZrpFhcnl+l/AuDQ6TK9/vUdJKVny9nKpa1R9Z179QF+1ahSkXanZks78RPWPhF36fNMhHc48pfyCQuWdLpS/T70qtWHixIkaP3688z4zM5NAAwBAHVatYeZ8zPpqt2avStbjw+PULiJEAb71NO2zbcorKKzSctxut9zu0j8/AQCAuqlaf2ZK3J/u8X7D/nS1aBSothHBOl1olLj/uDPv+Ik87TmarbYRQZKk7388riFxEbq+W3PFRYYoukGAko+e8Fier7eXCgtNdTYZAABYrlrDzMH0k3ris23afSRb8xMP6M1vftTo3i3UslGghsRF6JGPNmvtj2nadjBT97+fqCYhfhoSFyFJatEoUCuTjur7vWnalZqlR+dt1tESt4M1r++vxP3p2p+Wo7QTeQSbcxAe7NZ9g9oqPJizV0XOZ52wPnE+bBg/ZbXRhnbj/Nm0nV3GmGpJBDfOWq3YiGAVGqP/JB6Ul5dLt1werYeuaudxa/bi7SnKLyhUz5YNNbXYrdnpOXma8OEmfbPrqPx96+nmntE6kH5SWadO61+39ZAk7TmSrQfnbtT2Q5k6lV9YqVuzMzMzFRoaqoyMDIWEhFRHVwEAQA2ryvd3tYWZixVhBgAA+1Tl+5snAAMAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVvGu7ATXNGCNJyszMrOWWAACAyir63i76Hq9InQ8zWVlZkqSoqKhabgkAAKiqrKwshYaGVljGZSoTeSxWWFiogwcPyhij6Oho7d+/XyEhIbXdrBqVmZmpqKioOt/Xn0s/pZ9PX38u/ZR+Pn39ufRToq/VzRijrKwsRUZGysur4qti6vyZGS8vLzVv3tw5XRUSElLnB1mRn0tffy79lH4+ff259FP6+fT159JPib5Wp7OdkSnCBcAAAMBqhBkAAGC1n02Ycbvdmjx5stxud203pcb9XPr6c+mn9PPp68+ln9LPp68/l35K9LU21fkLgAEAQN32szkzAwAA6ibCDAAAsBphBgAAWI0wAwAArPazCDP/+Mc/1KJFC/n5+Sk+Pl7fffddbTfJw1dffaXhw4crMjJSLpdLn3zyicd8Y4wef/xxNW3aVP7+/ho8eLCSkpI8yqSlpWnEiBEKCQlRWFiY7rjjDmVnZ3uU2bRpk/r27Ss/Pz9FRUXp2WefLdWWuXPnqn379vLz81OnTp30xRdfVFs/p0+frssuu0zBwcEKDw/Xddddpx07dniUOXXqlMaOHauGDRsqKChIv/nNb5SSkuJRZt++fRo2bJgCAgIUHh6uCRMm6PTp0x5lli9frksvvVRut1tt2rTRnDlzSrWnJsfFq6++qs6dOzsPlOrVq5e+/PLLOtfPkmbMmCGXy6X777/fmVZX+jplyhS5XC6PV/v27etcP4scOHBAt9xyixo2bCh/f3916tRJ69atc+bXheNSixYtSm1Tl8ulsWPHSqpb27SgoEB/+ctf1LJlS/n7+6t169Z64oknPP7dI6u3qanj3nvvPePr62veeOMNs3XrVvOHP/zBhIWFmZSUlNpumuOLL74wkyZNMh9//LGRZObNm+cxf8aMGSY0NNR88sknZuPGjeaaa64xLVu2NCdPnnTK/OIXvzBdunQx3377rfn6669NmzZtzM033+zMz8jIMBEREWbEiBFmy5Yt5t///rfx9/c3s2bNcsqsWrXK1KtXzzz77LNm27Zt5rHHHjM+Pj5m8+bN1dLPoUOHmtmzZ5stW7aYxMRE88tf/tJER0eb7Oxsp8zdd99toqKizNKlS826devM5Zdfbq644gpn/unTp80ll1xiBg8ebDZs2GC++OIL06hRIzNx4kSnzJ49e0xAQIAZP3682bZtm3nppZdMvXr1zIIFC5wyNT0u/vOf/5jPP//c7Ny50+zYscM8+uijxsfHx2zZsqVO9bO47777zrRo0cJ07tzZ3Hfffc70utLXyZMnm44dO5pDhw45ryNHjtS5fhpjTFpamomJiTGjRo0ya9asMXv27DELFy40u3btcsrUheNSamqqx/ZcvHixkWQSEhKMMXVrmz711FOmYcOG5rPPPjPJyclm7ty5JigoyMycOdMpY/M2rfNhpmfPnmbs2LHO+4KCAhMZGWmmT59ei60qX8kwU1hYaJo0aWL++te/OtPS09ON2+02//73v40xxmzbts1IMmvXrnXKfPnll8blcpkDBw4YY4x55ZVXTP369U1ubq5T5s9//rNp166d8/6GG24ww4YN82hPfHy8ueuuu6q1j0VSU1ONJLNixQqnXz4+Pmbu3LlOme3btxtJZvXq1caYM8HPy8vLHD582Cnz6quvmpCQEKdvDz/8sOnYsaNHXTfeeKMZOnSo8742xkX9+vXN66+/Xif7mZWVZdq2bWsWL15s+vfv74SZutTXyZMnmy5dupQ5ry7105gzx4Y+ffqUO7+uHpfuu+8+07p1a1NYWFjntumwYcPM7bff7jHt17/+tRkxYoQxxv5tWqd/ZsrLy9P333+vwYMHO9O8vLw0ePBgrV69uhZbVnnJyck6fPiwRx9CQ0MVHx/v9GH16tUKCwtTjx49nDKDBw+Wl5eX1qxZ45Tp16+ffH19nTJDhw7Vjh07dPz4cadM8XqKytTUusrIyJAkNWjQQJL0/fffKz8/36MN7du3V3R0tEdfO3XqpIiICI82ZmZmauvWrZXqx4UeFwUFBXrvvfd04sQJ9erVq072c+zYsRo2bFip9tS1viYlJSkyMlKtWrXSiBEjtG/fvjrZz//85z/q0aOHfve73yk8PFzdunXTv/71L2d+XTwu5eXl6e2339btt98ul8tV57bpFVdcoaVLl2rnzp2SpI0bN2rlypW6+uqrJdm/Tet0mDl69KgKCgo8BpokRURE6PDhw7XUqqopamdFfTh8+LDCw8M95nt7e6tBgwYeZcpaRvE6yitTE+uqsLBQ999/v3r37q1LLrnEqd/X11dhYWHltuF8+pGZmamTJ09esHGxefNmBQUFye126+6779a8efMUFxdX5/r53nvvaf369Zo+fXqpeXWpr/Hx8ZozZ44WLFigV199VcnJyerbt6+ysrLqVD8lac+ePXr11VfVtm1bLVy4UPfcc4/GjRunN99806O9dem49Mknnyg9PV2jRo1y6q1L2/SRRx7RTTfdpPbt28vHx0fdunXT/fffrxEjRni019ZtWuf/1WxcnMaOHastW7Zo5cqVtd2UGtOuXTslJiYqIyNDH374oUaOHKkVK1bUdrOq1f79+3Xfffdp8eLF8vPzq+3m1Kii/4OVpM6dOys+Pl4xMTH64IMP5O/vX4stq36FhYXq0aOHnn76aUlSt27dtGXLFv3zn//UyJEja7l1NeP//u//dPXVVysyMrK2m1IjPvjgA73zzjt699131bFjRyUmJur+++9XZGRkndimdfrMTKNGjVSvXr1SV5+npKSoSZMmtdSqqilqZ0V9aNKkiVJTUz3mnz59WmlpaR5lylpG8TrKK1Pd6+ree+/VZ599poSEBDVv3tyZ3qRJE+Xl5Sk9Pb3cNpxPP0JCQuTv73/BxoWvr6/atGmj7t27a/r06erSpYtmzpxZp/r5/fffKzU1VZdeeqm8vb3l7e2tFStW6O9//7u8vb0VERFRZ/paUlhYmGJjY7Vr1646tU0lqWnTpoqLi/OY1qFDB+dntbp2XNq7d6+WLFmiMWPGONPq2jadMGGCc3amU6dOuvXWW/XAAw84Z1Rt36Z1Osz4+vqqe/fuWrp0qTOtsLBQS5cuVa9evWqxZZXXsmVLNWnSxKMPmZmZWrNmjdOHXr16KT09Xd9//71TZtmyZSosLFR8fLxT5quvvlJ+fr5TZvHixWrXrp3q16/vlCleT1GZ6lpXxhjde++9mjdvnpYtW6aWLVt6zO/evbt8fHw82rBjxw7t27fPo6+bN2/22KEWL16skJAQ5+B7tn7U1rgoLCxUbm5unernoEGDtHnzZiUmJjqvHj16aMSIEc7fdaWvJWVnZ2v37t1q2rRpndqmktS7d+9Sj03YuXOnYmJiJNWt45IkzZ49W+Hh4Ro2bJgzra5t05ycHHl5eX7l16tXT4WFhZLqwDY950uHLfHee+8Zt9tt5syZY7Zt22buvPNOExYW5nH1eW3LysoyGzZsMBs2bDCSzPPPP282bNhg9u7da4w5c7tcWFiYmT9/vtm0aZO59tpry7xdrlu3bmbNmjVm5cqVpm3bth63y6Wnp5uIiAhz6623mi1btpj33nvPBAQElLpdztvb2/ztb38z27dvN5MnT67WW7PvueceExoaapYvX+5xO2ROTo5T5u677zbR0dFm2bJlZt26daZXr16mV69ezvyiWyGvuuoqk5iYaBYsWGAaN25c5q2QEyZMMNu3bzf/+Mc/yrwVsibHxSOPPGJWrFhhkpOTzaZNm8wjjzxiXC6XWbRoUZ3qZ1mK381Ul/r64IMPmuXLl5vk5GSzatUqM3jwYNOoUSOTmppap/ppzJnb7L29vc1TTz1lkpKSzDvvvGMCAgLM22+/7ZSpK8elgoICEx0dbf785z+XmleXtunIkSNNs2bNnFuzP/74Y9OoUSPz8MMPO2Vs3qZ1PswYY8xLL71koqOjja+vr+nZs6f59ttva7tJHhISEoykUq+RI0caY87cMveXv/zFREREGLfbbQYNGmR27NjhsYxjx46Zm2++2QQFBZmQkBAzevRok5WV5VFm48aNpk+fPsbtdptmzZqZGTNmlGrLBx98YGJjY42vr6/p2LGj+fzzz6utn2X1UZKZPXu2U+bkyZPmj3/8o6lfv74JCAgw119/vTl06JDHcn788Udz9dVXG39/f9OoUSPz4IMPmvz8fI8yCQkJpmvXrsbX19e0atXKo44iNTkubr/9dhMTE2N8fX1N48aNzaBBg5wgU5f6WZaSYaau9PXGG280TZs2Nb6+vqZZs2bmxhtv9HjuSl3pZ5FPP/3UXHLJJcbtdpv27dub1157zWN+XTkuLVy40Egq1XZj6tY2zczMNPfdd5+Jjo42fn5+plWrVmbSpEket1DbvE1dxhR7/B8AAIBl6vQ1MwAAoO4jzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wA+CiNmDAAN1///3VtrwpU6YoIiJCLpdLn3zySbnTANiDMAOgXP/85z8VHBys06dPO9Oys7Pl4+OjAQMGeJRdvny5XC6Xdu/efYFbKZ08eVKTJ09WbGys3G63GjVqpN/97nfaunWrR7nt27dr6tSpmjVrlg4dOqSrr766zGnni1AEXFiEGQDlGjhwoLKzs7Vu3Tpn2tdff60mTZpozZo1OnXqlDM9ISFB0dHRat26dZXrMcZ4BKaqyM3N1eDBg/XGG2/oySef1M6dO/XFF1/o9OnTio+P17fffuuULQpa1157rZo0aSK3213mNAB2IcwAKFe7du3UtGlTLV++3Jm2fPlyXXvttWrZsqVHUFi+fLkGDhwo6UzAGDdunMLDw+Xn56c+ffpo7dq1HmVdLpe+/PJLde/eXW63WytXrtSJEyd02223KSgoSE2bNtVzzz131ja++OKLWr16tT777DPdcMMNiomJUc+ePfXRRx+pQ4cOuuOOO2SM0ZQpUzR8+HBJkpeXl1wuV5nTitrXs2dPBQYGKiwsTL1799bevXudOufPn69LL71Ufn5+atWqlaZOneqEsRYtWkiSrr/+erlcLuc9gJpDmAFQoYEDByohIcF5n5CQoAEDBqh///7O9JMnT2rNmjVOmHn44Yf10Ucf6c0339T69evVpk0bDR06VGlpaR7LfuSRRzRjxgxt375dnTt31oQJE7RixQrNnz9fixYt0vLly7V+/foK2/fuu+9qyJAh6tKli8d0Ly8vPfDAA9q2bZs2btyohx56SLNnz5YkHTp0SIcOHSpz2unTp3Xdddepf//+2rRpk1avXq0777zTCTpff/21brvtNt13333atm2bZs2apTlz5uipp56SJCe0zZ49W4cOHfIIcQBqyHn9M5UA6rx//etfJjAw0OTn55vMzEzj7e1tUlNTzbvvvmv69etnjDFm6dKlRpLZu3evyc7ONj4+Puadd95xlpGXl2ciIyPNs88+a4z5378U/8knnzhlsrKyjK+vr/nggw+caceOHTP+/v4e/wp3SX5+fuXOX79+vZFk3n//fWOMMfPmzTMlD3slpx07dsxIMsuXLy9zmYMGDTJPP/20x7S33nrLNG3a1HkvycybN6/cNgOoXt61mKMAWGDAgAE6ceKE1q5dq+PHjys2NlaNGzdW//79NXr0aJ06dUrLly9Xq1atFB0drU2bNik/P1+9e/d2luHj46OePXtq+/btHsvu0aOH8/fu3buVl5en+Ph4Z1qDBg3Url27s7bRGFMNPf1fnaNGjdLQoUM1ZMgQDR48WDfccIOaNm0qSdq4caNWrVrlnImRpIKCAp06dUo5OTkKCAiotrYAqBx+ZgJQoTZt2qh58+ZKSEhQQkKC+vfvL0mKjIxUVFSUvvnmGyUkJOjKK6+s8rIDAwPPu32xsbGlQlKRoumxsbFVWubs2bO1evVqXXHFFXr//fcVGxvrXB+UnZ2tqVOnKjEx0Xlt3rxZSUlJ8vPzO7/OADgnhBkAZzVw4EAtX75cy5cv97glu1+/fvryyy/13XffOdfLtG7dWr6+vlq1apVTLj8/X2vXrlVcXFy5dbRu3Vo+Pj5as2aNM+348ePauXNnhW276aabtGTJEm3cuNFjemFhoV544QXFxcWVup6mMrp166aJEyfqm2++0SWXXKJ3331XknTppZdqx44datOmTamXl9eZQ6qPj48KCgqqXCeAc8PPTADOauDAgRo7dqzy8/OdMzOS1L9/f917773Ky8tzwkxgYKDuueceTZgwQQ0aNFB0dLSeffZZ5eTk6I477ii3jqCgIN1xxx2aMGGCGjZsqPDwcE2aNMkJCOV54IEHNH/+fA0fPlzPPfec4uPjlZKSoqefflrbt2/XkiVLnIt3KyM5OVmvvfaarrnmGkVGRmrHjh1KSkrSbbfdJkl6/PHH9atf/UrR0dH67W9/Ky8vL23cuFFbtmzRk08+KenMHU1Lly5V79695Xa7Vb9+/UrXD6DqCDMAzmrgwIE6efKk2rdvr4iICGd6//79lZWV5dzCXWTGjBkqLCzUrbfeqqysLPXo0UMLFy4865f6X//6V2VnZ2v48OEKDg7Wgw8+qIyMjAo/4+fnp2XLlunpp5/Wo48+qr179yo4OFgDBw7Ut99+q0suuaRKfQ0ICNAPP/ygN998U8eOHVPTpk01duxY3XXXXZKkoUOH6rPPPtO0adP0zDPPyMfHR+3bt9eYMWOcZTz33HMaP368/vWvf6lZs2b68ccfq9QGAFXjMtV55RwAAMAFxjUzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFjt/wOQJYoIgHxB9wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "textList.dispersion_plot([\"boat\", \"dog\", \"river\", \"lunch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By default tokenization includes all surrounting punctuation charachters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81185"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(textList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can invoke RegexpTokenizer to eliminate punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68364"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This will match any word characters until it reaches a non-word character, like a space\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens = tokenizer.tokenize(bk_3boat)\n",
    "\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring lexical diversity: dividing unique words by overall words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09222146948327893"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(textList)) / len(textList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lex_diversity_pct(text):\n",
    "    return (len(set(textList)) / len(textList))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.222146948327893"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex_diversity_pct(textList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text normalization with stemming and lemmatization\n",
    "\n",
    "The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form. For instance:\n",
    "\n",
    "    am, are, is =>  be\n",
    "    dog, dogs, dog's, dogs' => dog\n",
    "\n",
    "The result of this mapping of text will be something like:\n",
    "\n",
    "    the girl's dogs are different breeds => the girl dog be differ breed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting lists to strings to simplify displaying / visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_l = (words_lc[0:50])\n",
    "words_s = ', '.join(words_l)\n",
    "type (words_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'maladies', 'useful', 'prescriptions', 'cure', 'liver', 'complaint', 'children', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodges', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print (words_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'noth', 'dog', 'three', 'men', 'boat', 'jerom', 'jerom', 'chapter', 'three', 'invalid', 'suffer', 'georg', 'harri', 'victim', 'one', 'hundr', 'seven', 'fatal', 'maladi', 'use', 'prescript', 'cure', 'liver', 'complaint', 'children', 'agre', 'overwork', 'need', 'rest', 'week', 'roll', 'deep', 'georg', 'suggest', 'river', 'montmor', 'lodg', 'object', 'origin', 'motion', 'carri', 'major', 'three', 'one', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print([porter.stem(t) for t in words_lc[0:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'noth', 'dog', 'three', 'men', 'boat', 'jerom', 'jerom', 'chapt', 'three', 'invalid', 'suff', 'georg', 'har', 'victim', 'on', 'hundr', 'sev', 'fat', 'malady', 'us', 'prescrib', 'cur', 'liv', 'complaint', 'childr', 'agr', 'overwork', 'nee', 'rest', 'week', 'rol', 'deep', 'georg', 'suggest', 'riv', 'montm', 'lodg', 'object', 'origin', 'mot', 'carry', 'maj', 'three', 'on', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print([lancaster.stem(t) for t in words_lc[0:50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma.\n",
    "\n",
    "The WordNet lemmatizer only removes affixes if the resulting word is in its dictionary. The dictionary checking makes lemmatizers significantly slower than stemmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'maladies', 'useful', 'prescriptions', 'cure', 'liver', 'complaint', 'children', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodges', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print (words_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalid', 'suffering', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'malady', 'useful', 'prescription', 'cure', 'liver', 'complaint', 'child', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodge', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'u']\n"
     ]
    }
   ],
   "source": [
    "print([wnl.lemmatize(t) for t in words_lc[0:50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can use help function to get explanations of endividual tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc1 = \"The University of Chicago is a private research university in Chicago, Illinois\"\n",
    "uc2 = \"It is one of the world's leading and most influential institutions of higher learning, with top-ten positions in numerous rankings and measures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('private', 'JJ'),\n",
       " ('research', 'NN'),\n",
       " ('university', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " (',', ','),\n",
       " ('Illinois', 'NNP')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.tokenize.word_tokenize(uc1)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('IN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('leading', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('most', 'JJS'),\n",
       " ('influential', 'JJ'),\n",
       " ('institutions', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('higher', 'JJR'),\n",
       " ('learning', 'NN'),\n",
       " (',', ','),\n",
       " ('with', 'IN'),\n",
       " ('top-ten', 'JJ'),\n",
       " ('positions', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('numerous', 'JJ'),\n",
       " ('rankings', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('measures', 'NNS')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.tokenize.word_tokenize(uc2)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('CC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all possible tags and values\n",
    "# nltk.help.upenn_tagset('.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from URL\n",
    "#### BeautifulSoup to clean up meta-tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/University_of_Chicago\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "page = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(page.read(), \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for classes on October 1, 1892.[39]  Harper worked on building up the faculty and in two years he had a faculty of 120, including eight former university or college presidents.[44]  Harper was an accomplished scholar (Semiticist) and a member of the Baptist clergy who believed that a great university should maintain the study of faith as a central focus.[45] To fulfill this commitment, he brought the Baptist seminary that had begun as an independent school \"alongside\" the Old University of Chicago and separated from the old school decades earlier to Morgan Park. This became the Divinity School in 1891, the first professional school at the University of Chicago.[35]: 20–22 \n",
      "Harper recruited acclaimed Yale baseball and football player Amos Alonzo Stagg from the Young Men's Christian Association training school at Springfield to coach the school's football program. Stagg was given a position on the faculty, the first such athletic position in the United States. While coaching at the university, Stagg invented the numbered football jersey, the huddle, and the lighted playing field.  Stagg is the namesake of the university's Stagg Field.[46]\n",
      "The business school was founded in 1898,[47] and the law school was founded in 1902.[48] Harper died in 1906[49] and was replaced by a succession of three presidents whose tenures lasted until 1929.[50] During this period, the Oriental Institute was founded to support and interpret archeological work in what was then called the Near East.[51]\n",
      "In the 1890s, the university, fearful that its vast resources would injure smaller schools by drawing away good students, affiliated with several regional colleges and universities: Des Moines College, Kalamazoo College, Butler University, and Stetson University. In 1896, the university affiliated with Shimer College in Mount Carroll, Illinois. Under the terms of the affiliation, the schools were required to have courses of study comparable to those at the university, to notify the university early of any contemplated faculty appointments or dismissals, to make no faculty appointment\n"
     ]
    }
   ],
   "source": [
    "uc_wiki = (soup.get_text())\n",
    "#print (type(uc_wiki))\n",
    "print (uc_wiki[6910:9000]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even after BeautifulSoup we are left with a lot of garbade - mostly punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['of', 'Chicago', 'team', 'that', 'worked', 'on', 'the', 'production', 'of', 'the', 'world', \"'s\", 'first', 'human-caused', 'self-sustaining', 'nuclear', 'reaction', ',', 'including', 'Enrico', 'Fermi', 'in', 'the', 'front', 'row', 'and', 'Leó', 'Szilárd', 'in', 'the', 'second', '.', 'Money', 'that', 'had', 'been', 'raised', 'during', 'the', '1920s', 'and', 'financial', 'backing', 'from', 'the', 'Rockefeller', 'Foundation', 'helped', 'the', 'school', 'to', 'survive', 'through', 'the', 'Great', 'Depression', '.', '[', '54', ']', 'Nonetheless', ',', 'in', '1933', ',', 'Hutchins', 'proposed', 'an', 'unsuccessful', 'plan', 'to', 'merge', 'the', 'University', 'of', 'Chicago', 'and', 'Northwestern', 'University', 'into', 'a', 'single', 'university', '.', '[', '57', ']', 'During', 'World', 'War', 'II', ',', 'the', 'university', \"'s\", 'Metallurgical', 'Laboratory', 'made', 'ground-breaking', 'contributions']\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_tokens = nltk.tokenize.word_tokenize(uc_wiki)\n",
    "uc_wiki_tokens_uncleaned = uc_wiki_tokens\n",
    "print (uc_wiki_tokens[2000:2100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('University', 329),\n",
       " ('Chicago', 321),\n",
       " ('The', 198),\n",
       " ('Retrieved', 177),\n",
       " ('Archived', 137),\n",
       " ('original', 134),\n",
       " ('university', 129),\n",
       " ('School', 76),\n",
       " ('College', 73),\n",
       " ('September', 57)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stopwords = stopwords.words('english')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Remove single-character tokens (mostly punctuation)\n",
    "uc_wiki_tokens = [word for word in uc_wiki_tokens if len(word) > 1]\n",
    "\n",
    "# Remove punctuation\n",
    "uc_wiki_tokens = [word for word in uc_wiki_tokens if word.isalpha()]\n",
    "\n",
    "# Remove stopwords\n",
    "uc_wiki_tokens_no_stopwords = [word for word in uc_wiki_tokens if word not in stopwords]\n",
    "\n",
    "fdist = nltk.FreqDist(uc_wiki_tokens_no_stopwords)\n",
    "\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the results of our cleaned web scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanest version with all noise and stopwords removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['University', 'Chicago', 'Wikipedia', 'University', 'Chicago', 'From', 'Wikipedia', 'free', 'encyclopedia', 'Jump', 'navigation', 'Jump', 'search', 'Private', 'university', 'Chicago', 'Illinois', 'The', 'University', 'ChicagoLatin', 'Universitas', 'ChicaginiensisMottoCrescat', 'scientia', 'vita', 'excolatur', 'Latin', 'Motto', 'English', 'Let', 'knowledge', 'grow', 'human', 'life', 'enriched', 'TypePrivate', 'research', 'AccreditationHLCAcademic', 'billion', 'PresidentA', 'Paul', 'AlivisatosProvostKa', 'Yee', 'Christina', 'LeeAcademic', 'Administrative', 'including', 'employees', 'The', 'University', 'Chicago', 'Medical', 'Center', 'LocationChicago', 'Illinois', 'United', 'City', 'acres', 'ha', 'main', 'campus', 'Warren', 'Woods', 'Ecological', 'Field', 'Station', 'Warren', 'Woods', 'State', 'Park', 'acres', 'ha', 'NewspaperThe', 'Chicago', 'MaroonColors', 'Maroon', 'NicknameMaroonsSporting', 'affiliationsNCAA', 'Division', 'III', 'UAAMascotPhil', 'The', 'University', 'Chicago', 'UChicago', 'Chicago', 'UChi', 'private', 'research', 'university', 'Chicago', 'Illinois', 'Its', 'main', 'campus', 'located', 'Chicago', 'Hyde', 'Park', 'neighborhood', 'The']\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_no_stopwords = nltk.Text(uc_wiki_tokens_no_stopwords)\n",
    "print (uc_wiki_text_no_stopwords[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modest cleaning - only punctuation and noise - all stopwords left intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['University', 'of', 'Chicago', 'Wikipedia', 'University', 'of', 'Chicago', 'From', 'Wikipedia', 'the', 'free', 'encyclopedia', 'Jump', 'to', 'navigation', 'Jump', 'to', 'search', 'Private', 'university', 'in', 'Chicago', 'Illinois', 'The', 'University', 'of', 'ChicagoLatin', 'Universitas', 'ChicaginiensisMottoCrescat', 'scientia', 'vita', 'excolatur', 'Latin', 'Motto', 'in', 'English', 'Let', 'knowledge', 'grow', 'from', 'more', 'to', 'more', 'and', 'so', 'be', 'human', 'life', 'enriched', 'TypePrivate', 'research', 'AccreditationHLCAcademic', 'billion', 'PresidentA', 'Paul', 'AlivisatosProvostKa', 'Yee', 'Christina', 'LeeAcademic', 'Administrative', 'including', 'employees', 'of', 'The', 'University', 'of', 'Chicago', 'Medical', 'Center', 'LocationChicago', 'Illinois', 'United', 'City', 'acres', 'ha', 'main', 'campus', 'Warren', 'Woods', 'Ecological', 'Field', 'Station', 'Warren', 'Woods', 'State', 'Park', 'acres', 'ha', 'NewspaperThe', 'Chicago', 'MaroonColors', 'Maroon', 'NicknameMaroonsSporting', 'affiliationsNCAA', 'Division', 'III', 'UAAMascotPhil', 'the', 'The', 'University']\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_cleaned = nltk.Text(uc_wiki_tokens)\n",
    "print (uc_wiki_text_cleaned[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No cleaning done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['University', 'of', 'Chicago', '-', 'Wikipedia', 'University', 'of', 'Chicago', 'From', 'Wikipedia', ',', 'the', 'free', 'encyclopedia', 'Jump', 'to', 'navigation', 'Jump', 'to', 'search', 'Private', 'university', 'in', 'Chicago', ',', 'Illinois', 'The', 'University', 'of', 'ChicagoLatin', ':', 'Universitas', 'ChicaginiensisMottoCrescat', 'scientia', ';', 'vita', 'excolatur', '(', 'Latin', ')', 'Motto', 'in', 'English', \"''\", 'Let', 'knowledge', 'grow', 'from', 'more', 'to', 'more', ';', 'and', 'so', 'be', 'human', 'life', 'enriched', '.', '``', '[', '1', ']', 'TypePrivate', 'research', 'universityEstablished1890', '[', '1856', ']', '(', '1890', '[', '1856', ']', ')', '[', '1', ']', '[', '2', ']', 'AccreditationHLCAcademic', 'affiliationsAAUNAICUURASpace-grantEndowment', '$', '11.6', 'billion', '(', '2021', ')', '[', '3', ']', 'PresidentA', '.', 'Paul', 'AlivisatosProvostKa', 'Yee', 'Christina', 'LeeAcademic', 'staff2,859']\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_raw = nltk.Text(uc_wiki_tokens_uncleaned)\n",
    "print (uc_wiki_text_raw[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying simlarity function - which option produces best results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanest version with all noise and stopwords removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site chicago illinois the campus maroon uchicago located college\n",
      "science history arts sororities buildings classes reputation economist\n",
      "chairman kind spurs\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_no_stopwords.similar('university')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modest cleaning - only punctuation and noise - all stopwords left intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "college class chicago world school faculty board campus history arts\n",
      "law as development president professor study institute office team\n",
      "site\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_cleaned.similar('university')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No cleaning done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "college class chicago world school faculty board campus arts law as\n",
      "development history president professor study institute office site\n",
      "new\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_raw.similar('university')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging our web page with POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order for the tagger to be effective, it has to tag each word based on the word itself, as well as its context within a sentence. \n",
    "Depending on your corpus, certain taggers perform better the others.  Like with SPSS TA dictionaries, you can start with pre-trained POS Tagger and then try multiple different options to see which one will perform best for you.\n",
    "You can also customize and train your own taggers to match your particular corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc_wiki_tagged = nltk.pos_tag(uc_wiki_text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(uc_wiki_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " ('Wikipedia', 'NNP'),\n",
       " ('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " ('From', 'NNP'),\n",
       " ('Wikipedia', 'NNP'),\n",
       " ('the', 'DT')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uc_wiki_tagged[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring alternative text analysis packages: TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(uc_wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('9', 'CD'),\n",
       " (']', 'VBD'),\n",
       " ('The', 'DT'),\n",
       " ('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('consistently', 'RB'),\n",
       " ('ranked', 'VBN'),\n",
       " ('among', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('best', 'JJS'),\n",
       " ('universities', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('[', 'VBZ'),\n",
       " ('10', 'CD'),\n",
       " (']', 'NN'),\n",
       " ('[', 'VBD')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags[200:220]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To process  cleaned-up version from NLTK we will have to convert text from nltk.text.Text to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(uc_wiki_text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "words_list = (uc_wiki_text_cleaned[0:])\n",
    "words_string = ', '.join(words)\n",
    "print(type(words_list))\n",
    "print(type(words_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(words_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS Tagging with TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TO', 'NNP'),\n",
       " ('ONE', 'NNP'),\n",
       " ('THERE', 'NNP'),\n",
       " ('were', 'VBD'),\n",
       " ('four', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('us', 'PRP'),\n",
       " ('George', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('William', 'NNP'),\n",
       " ('Samuel', 'NNP'),\n",
       " ('Harris', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('myself', 'PRP'),\n",
       " ('and', 'CC'),\n",
       " ('Montmorency', 'NNP'),\n",
       " ('We', 'PRP'),\n",
       " ('were', 'VBD'),\n",
       " ('sitting', 'VBG'),\n",
       " ('in', 'IN')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags[70:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('four', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('us', 'PRP'),\n",
       " ('George', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('William', 'NNP'),\n",
       " ('Samuel', 'NNP'),\n",
       " ('Harris', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('myself', 'PRP'),\n",
       " ('and', 'CC'),\n",
       " ('Montmorency', 'NNP'),\n",
       " ('We', 'PRP'),\n",
       " ('were', 'VBD'),\n",
       " ('sitting', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('room', 'NN'),\n",
       " ('smoking', 'NN'),\n",
       " ('and', 'CC')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.tokenize.word_tokenize(bk_3boat)\n",
    "words_string = ', '.join(words)\n",
    "blob = TextBlob(words_string)\n",
    "\n",
    "blob.tags[80:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tripping on the capitalized header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('THREE', 'CD'),\n",
       " ('MEN', 'NNP'),\n",
       " ('IN', 'NNP'),\n",
       " ('A', 'NNP'),\n",
       " ('BOAT', 'NNP'),\n",
       " ('TO', 'NNP'),\n",
       " ('SAY', 'NNP'),\n",
       " ('NOTHING', 'NNP'),\n",
       " ('OF', 'NNP'),\n",
       " ('THE', 'NNP')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['three', 'men', 'in', 'boat', 'to', 'say', 'nothing', 'of', 'the', 'dog', 'men', 'boat', 'jerome', 'k.', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'of', 'george', 'and', 'harris', 'victim', 'to', 'one', 'hundred', 'and', 'seven', 'fatal', 'maladies', 'useful', 'prescriptions', 'cure', 'for', 'liver', 'complaint', 'in', 'children', 'we', 'agree', 'that', 'we', 'are', 'overworked', 'and', 'need', 'rest', 'week', 'on'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.noun_phrases[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Be careful with embedded functions to pluralize and singularize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = TextBlob(words_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'maladies', 'useful', 'prescriptions', 'cure', 'liver', 'complaint', 'children', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodges', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print(words_l[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['three', 'man', 'boat', 'say', 'nothing', 'dog', 'three', 'man', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalid', 'suffering', 'george', 'harri', 'victim', 'one', 'hundred', 'seven', 'fatal', 'malady', 'useful', 'prescription', 'cure', 'liver', 'complaint', 'child', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggest', 'river', 'montmorency', 'lodge', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'fmy', 'u'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.words[:100].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'maladies', 'useful', 'prescriptions', 'cure', 'liver', 'complaint', 'children', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodges', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print(words_l[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['threes', 'mens', 'boats', 'says', 'nothings', 'dogs', 'threes', 'mens', 'boats', 'jeromes', 'jeromes', 'chapters', 'threes', 'invalidss', 'sufferingss', 'georges', 'harriss', 'victims', 'ones', 'hundreds', 'sevens', 'fatals', 'maladiess', 'usefuls', 'prescriptionss', 'cures', 'livers', 'complaints', 'childrens', 'agrees', 'overworkeds', 'needs', 'rests', 'weeks', 'rollings', 'deeps', 'georges', 'suggestss', 'rivers', 'montmorencies', 'lodgess', 'objections', 'originals', 'motions', 'carrieds', 'majorities', 'threes', 'ones', 'fours', 'uss'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.words[0:100].pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'maladies', 'useful', 'prescriptions', 'cure', 'liver', 'complaint', 'children', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodges', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'us'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.words[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalid', 'suffering', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'malady', 'useful', 'prescription', 'cure', 'liver', 'complaint', 'child', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodge', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'u'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.words[0:100].lemmatize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_wiki = TextBlob(uc_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Harper', 'worked', 'on', 'building', 'up', 'the', 'faculty', 'and', 'in', 'two', 'years', 'he', 'had', 'a', 'faculty', 'of', '120', 'including', 'eight', 'former', 'university', 'or', 'college', 'presidents', '44', 'Harper', 'was', 'an', 'accomplished', 'scholar', 'Semiticist', 'and', 'a', 'member', 'of', 'the', 'Baptist', 'clergy', 'who', 'believed', 'that', 'a', 'great', 'university', 'should', 'maintain', 'the', 'study', 'of', 'faith', 'as', 'a', 'central', 'focus', '45', 'To', 'fulfill', 'this', 'commitment', 'he']\n"
     ]
    }
   ],
   "source": [
    "b_words = blob_wiki.words\n",
    "print (b_words[1020:1080])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'class', '1.1.3', 'is', 'almost', 'over', 'Time', 'to', 'go', 'party', 'now']\n"
     ]
    }
   ],
   "source": [
    "blob_custom = TextBlob('The class 1.1.3 is almost over!!!  Time to go party now.')\n",
    "b_words = blob_custom.words\n",
    "print (b_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split to sentenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"[24]  Advances in chemistry led to the \"radiocarbon revolution\" in the carbon-14 dating of ancient life and objects.\"), Sentence(\"[25] The university research efforts include administration of Fermi National Accelerator Laboratory and Argonne National Laboratory, as well as the Marine Biological Laboratory.\"), Sentence(\"The university is also home to the University of Chicago Press, the largest university press in the United States.\"), Sentence(\"[26]\n",
      "The University of Chicago's students, faculty, and staff include 94 Nobel laureates, among the highest of any university in the world.\"), Sentence(\"[27] The university's faculty members and alumni also include 10 Fields Medalists,[28] 4 Turing Award winners, 52 MacArthur Fellows,[29] 26 Marshall Scholars,[30] 53 Rhodes Scholars,[31] 27 Pulitzer Prize winners,[32] 20 National Humanities Medalists,[33] 29 living billionaire graduates,[34] and eight Olympic medalists.\")]\n"
     ]
    }
   ],
   "source": [
    "b_sentences = blob_wiki.sentences\n",
    "print (b_sentences[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"I need to go to Dr. now NLP is So.\"), Sentence(\"boring...\"), Sentence(\"I want to end this Zoom session now.\")]\n"
     ]
    }
   ],
   "source": [
    "blob_custom = TextBlob('''I need to go to Dr. now NLP is So. boring... I want to end this Zoom session now.''')\n",
    "b_sentences = blob_custom.sentences\n",
    "print (b_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"The class 1, 2, etc.\"), Sentence(\"are almost over!!!\"), Sentence(\"Time to go to to U.S.A. next 34 Dr. Yuri's party 1.2. now.\")]\n"
     ]
    }
   ],
   "source": [
    "blob_custom = TextBlob('''The class 1, 2, etc. are almost over!!!  Time to go to to U.S.A. next 34 Dr. Yuri's party 1.2. now.''')\n",
    "b_sentences = blob_custom.sentences\n",
    "print (b_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon, 20 June 2022 19:57:06'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "datetime.datetime.now(pytz.timezone('US/Central')).strftime(\"%a, %d %B %Y %H:%M:%S\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
